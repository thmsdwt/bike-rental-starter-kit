{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripdata_files = glob.glob(\"data/JC-*-citibike-tripdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citibike data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for filename in tripdata_files:\n",
    "  data = pd.read_csv(filename)\n",
    "  df_list.append(data)\n",
    "\n",
    "citibike_tripdata = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_data = pd.read_csv(\"data/newark_airport_2016.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citibike - Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Trip Duration           Start Time            Stop Time  Start Station ID  \\\n",
      "0            361  2016-02-01 00:31:18  2016-02-01 00:37:19              3202   \n",
      "1            297  2016-02-01 01:55:05  2016-02-01 02:00:02              3195   \n",
      "2           1155  2016-02-01 02:40:05  2016-02-01 02:59:20              3183   \n",
      "3           1769  2016-02-01 05:11:28  2016-02-01 05:40:58              3214   \n",
      "4            935  2016-02-01 05:48:24  2016-02-01 06:03:59              3203   \n",
      "\n",
      "  Start Station Name  Start Station Latitude  Start Station Longitude  \\\n",
      "0       Newport PATH               40.727224               -74.033759   \n",
      "1            Sip Ave               40.730743               -74.063784   \n",
      "2     Exchange Place               40.716247               -74.033459   \n",
      "3   Essex Light Rail               40.712774               -74.036486   \n",
      "4      Hamilton Park               40.727596               -74.044247   \n",
      "\n",
      "   End Station ID  End Station Name  End Station Latitude  \\\n",
      "0            3203     Hamilton Park             40.727596   \n",
      "1            3194   McGinley Square             40.725340   \n",
      "2            3210    Pershing Field             40.742677   \n",
      "3            3203     Hamilton Park             40.727596   \n",
      "4            3214  Essex Light Rail             40.712774   \n",
      "\n",
      "   End Station Longitude  Bike ID   User Type  Birth Year  Gender  \n",
      "0             -74.044247    24393  Subscriber      1975.0       1  \n",
      "1             -74.067622    24394  Subscriber      1985.0       2  \n",
      "2             -74.051789    24676  Subscriber      1976.0       1  \n",
      "3             -74.044247    24700  Subscriber      1974.0       2  \n",
      "4             -74.036486    24639  Subscriber      1974.0       2  \n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 247584 entries, 0 to 19487\n",
      "Data columns (total 15 columns):\n",
      " #   Column                   Non-Null Count   Dtype  \n",
      "---  ------                   --------------   -----  \n",
      " 0   Trip Duration            247584 non-null  int64  \n",
      " 1   Start Time               247584 non-null  object \n",
      " 2   Stop Time                247584 non-null  object \n",
      " 3   Start Station ID         247584 non-null  int64  \n",
      " 4   Start Station Name       247584 non-null  object \n",
      " 5   Start Station Latitude   247584 non-null  float64\n",
      " 6   Start Station Longitude  247584 non-null  float64\n",
      " 7   End Station ID           247584 non-null  int64  \n",
      " 8   End Station Name         247584 non-null  object \n",
      " 9   End Station Latitude     247584 non-null  float64\n",
      " 10  End Station Longitude    247584 non-null  float64\n",
      " 11  Bike ID                  247584 non-null  int64  \n",
      " 12  User Type                247204 non-null  object \n",
      " 13  Birth Year               228585 non-null  float64\n",
      " 14  Gender                   247584 non-null  int64  \n",
      "dtypes: float64(5), int64(5), object(5)\n",
      "memory usage: 30.2+ MB\n",
      "None\n",
      "Trip Duration                  0\n",
      "Start Time                     0\n",
      "Stop Time                      0\n",
      "Start Station ID               0\n",
      "Start Station Name             0\n",
      "Start Station Latitude         0\n",
      "Start Station Longitude        0\n",
      "End Station ID                 0\n",
      "End Station Name               0\n",
      "End Station Latitude           0\n",
      "End Station Longitude          0\n",
      "Bike ID                        0\n",
      "User Type                    380\n",
      "Birth Year                 18999\n",
      "Gender                         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.info())\n",
    "print(citibike_tripdata.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "19483    False\n",
      "19484    False\n",
      "19485    False\n",
      "19486    False\n",
      "19487    False\n",
      "Length: 247584, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.duplicated())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Citibike - data preparation\n",
    "\n",
    "- remove unwanted columns\n",
    "- fix Null entries\n",
    "- Change Birth year entries to integer instead of float\n",
    "- Split start and stop time columns\n",
    "- Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "citibike_tripdata = citibike_tripdata[['Trip Duration', 'Start Time', 'Stop Time', 'Start Station ID',\n",
    "       'Start Station Name', #'Start Station Latitude',\n",
    "       #'Start Station Longitude',\n",
    "       'End Station ID',\n",
    "       'End Station Name',\n",
    "       #'End Station Latitude', 'End Station Longitude',\n",
    "       'Bike ID', 'User Type',\n",
    "       'Birth Year', 'Gender']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Birth year column\n",
    "# first NaN must be replaced with 0\n",
    "# change float to integer\n",
    "\n",
    "citibike_tripdata['Birth Year'] = citibike_tripdata['Birth Year'].fillna(0)\n",
    "citibike_tripdata['Birth Year'] = citibike_tripdata['Birth Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user type column\n",
    "# Replce NaN with 'Unknown'\n",
    "\n",
    "citibike_tripdata['User Type'] = citibike_tripdata['User Type'].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 247584 entries, 0 to 19487\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   Trip Duration       247584 non-null  int64 \n",
      " 1   Start Time          247584 non-null  object\n",
      " 2   Stop Time           247584 non-null  object\n",
      " 3   Start Station ID    247584 non-null  int64 \n",
      " 4   Start Station Name  247584 non-null  object\n",
      " 5   End Station ID      247584 non-null  int64 \n",
      " 6   End Station Name    247584 non-null  object\n",
      " 7   Bike ID             247584 non-null  int64 \n",
      " 8   User Type           247584 non-null  object\n",
      " 9   Birth Year          247584 non-null  int64 \n",
      " 10  Gender              247584 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 22.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"Start Time\" column\n",
    "\n",
    "citibike_tripdata[['start_date', 'start_time']] = citibike_tripdata['Start Time'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Trip Duration', 'Start Time', 'Stop Time', 'Start Station ID',\n",
      "       'Start Station Name', 'End Station ID', 'End Station Name', 'Bike ID',\n",
      "       'User Type', 'Birth Year', 'Gender', 'start_date', 'start_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split \"Stop Time\" column\n",
    "\n",
    "citibike_tripdata[['stop_date', 'stop_time']] = citibike_tripdata['Stop Time'].str.split(' ', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "# 'Start Time' column becomes start_date_time, because of the date and time combined it is a perfect Primary Key\n",
    "\n",
    "citibike_tripdata = citibike_tripdata.rename(columns={\n",
    "    'Trip Duration': 'trip_duration',\n",
    "    'Start Time': 'start_date_time',\n",
    "    'Start Station ID': 'start_station_id',\n",
    "    'Start Station Name': 'start_station_name',\n",
    "    'End Station Name': 'end_station_name',\n",
    "    'End Station ID': 'end_station_id',\n",
    "    'Bike ID': 'bike_id',\n",
    "    'User Type': 'user_type',\n",
    "    'Birth Year': 'birth_year',\n",
    "    'Gender': 'gender'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old stop time columns\n",
    "\n",
    "citibike_tripdata = citibike_tripdata[['trip_duration', 'start_date_time', #'Stop Time',\n",
    "                                        'start_station_id',\n",
    "       'start_station_name', 'end_station_id', 'end_station_name', 'bike_id',\n",
    "       'user_type', 'birth_year', 'gender', 'start_date', 'start_time',\n",
    "       'stop_date', 'stop_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['trip_duration', 'start_date_time', 'start_station_id',\n",
      "       'start_station_name', 'end_station_id', 'end_station_name', 'bike_id',\n",
      "       'user_type', 'birth_year', 'gender', 'start_date', 'start_time',\n",
      "       'stop_date', 'stop_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(citibike_tripdata.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_citibike_tripdata = citibike_tripdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather - Exploratory Data Analysis\n",
    "\n",
    "From data documentation:\\\n",
    "Note: 9â€™s in a field (e.g.9999) indicate missing data or data that has not been received.\\\n",
    "The five core values are:\n",
    "\n",
    "- PRCP = Precipitation (mm or inches as per user preference, inches to hundredths on Daily Form pdf file)\n",
    "- SNOW = Snowfall (mm or inches as per user preference, inches to tenths on Daily Form pdf file)\n",
    "- SNWD = Snow depth (mm or inches as per user preference, inches on Daily Form pdf file)\n",
    "- TMAX = Maximum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on\n",
    "Daily Form pdf file\n",
    "- TMIN = Minimum temperature (Fahrenheit or Celsius as per user preference, Fahrenheit to tenths on\n",
    "Daily Form pdf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION                                         NAME        DATE  \\\n",
      "0  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-01   \n",
      "1  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-02   \n",
      "2  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-03   \n",
      "3  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-04   \n",
      "4  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT, NJ US  2016-01-05   \n",
      "\n",
      "    AWND  PGTM  PRCP  SNOW  SNWD  TAVG  TMAX  TMIN  TSUN  WDF2   WDF5  WSF2  \\\n",
      "0  12.75   NaN   0.0   0.0   0.0    41    43    34   NaN   270  280.0  25.9   \n",
      "1   9.40   NaN   0.0   0.0   0.0    36    42    30   NaN   260  260.0  21.0   \n",
      "2  10.29   NaN   0.0   0.0   0.0    37    47    28   NaN   270  250.0  23.9   \n",
      "3  17.22   NaN   0.0   0.0   0.0    32    35    14   NaN   330  330.0  25.9   \n",
      "4   9.84   NaN   0.0   0.0   0.0    19    31    10   NaN   360  350.0  25.1   \n",
      "\n",
      "   WSF5  \n",
      "0  35.1  \n",
      "1  25.1  \n",
      "2  30.0  \n",
      "3  33.1  \n",
      "4  31.1  \n"
     ]
    }
   ],
   "source": [
    "print(weather_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 366 entries, 0 to 365\n",
      "Data columns (total 16 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   STATION  366 non-null    object \n",
      " 1   NAME     366 non-null    object \n",
      " 2   DATE     366 non-null    object \n",
      " 3   AWND     366 non-null    float64\n",
      " 4   PGTM     0 non-null      float64\n",
      " 5   PRCP     366 non-null    float64\n",
      " 6   SNOW     366 non-null    float64\n",
      " 7   SNWD     366 non-null    float64\n",
      " 8   TAVG     366 non-null    int64  \n",
      " 9   TMAX     366 non-null    int64  \n",
      " 10  TMIN     366 non-null    int64  \n",
      " 11  TSUN     0 non-null      float64\n",
      " 12  WDF2     366 non-null    int64  \n",
      " 13  WDF5     364 non-null    float64\n",
      " 14  WSF2     366 non-null    float64\n",
      " 15  WSF5     364 non-null    float64\n",
      "dtypes: float64(9), int64(4), object(3)\n",
      "memory usage: 45.9+ KB\n",
      "None\n",
      "STATION      0\n",
      "NAME         0\n",
      "DATE         0\n",
      "AWND         0\n",
      "PGTM       366\n",
      "PRCP         0\n",
      "SNOW         0\n",
      "SNWD         0\n",
      "TAVG         0\n",
      "TMAX         0\n",
      "TMIN         0\n",
      "TSUN       366\n",
      "WDF2         0\n",
      "WDF5         2\n",
      "WSF2         0\n",
      "WSF5         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(weather_data.info())\n",
    "print(weather_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with Null entries:\n",
    "- PGTM (complete column)\n",
    "- TSUN (complete column)\n",
    "- WDF5 (2 Null entries)\n",
    "- WSF5 (2 Null entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      False\n",
      "1      False\n",
      "2      False\n",
      "3      False\n",
      "4      False\n",
      "       ...  \n",
      "361    False\n",
      "362    False\n",
      "363    False\n",
      "364    False\n",
      "365    False\n",
      "Length: 366, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(weather_data.duplicated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      False\n",
       "1      False\n",
       "2      False\n",
       "3      False\n",
       "4      False\n",
       "       ...  \n",
       "361    False\n",
       "362    False\n",
       "363    False\n",
       "364    False\n",
       "365    False\n",
       "Length: 366, dtype: bool"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# search for use of 9999 as value\n",
    "\n",
    "weather_data.eq(9999).any(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather - data preparation\n",
    "\n",
    "- remove unwanted columns\n",
    "- Split NAME column\n",
    "- fix Null entries\n",
    "- Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove columns \n",
    "weather_data = weather_data[['STATION', 'NAME', 'DATE', 'AWND', #'PGTM',\n",
    "                             'PRCP', 'SNOW', 'SNWD',\n",
    "       'TAVG', 'TMAX', 'TMIN', #'TSUN',\n",
    "       #'WDF2', 'WDF5', 'WSF2', 'WSF5'\n",
    "       ]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       STATION                                  NAME        DATE   AWND  PRCP  \\\n",
      "0  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT  2016-01-01  12.75   0.0   \n",
      "1  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT  2016-01-02   9.40   0.0   \n",
      "2  USW00014734  NEWARK LIBERTY INTERNATIONAL AIRPORT  2016-01-03  10.29   0.0   \n",
      "\n",
      "   SNOW  SNWD  TAVG  TMAX  TMIN   STATE  \n",
      "0   0.0   0.0    41    43    34   NJ US  \n",
      "1   0.0   0.0    36    42    30   NJ US  \n",
      "2   0.0   0.0    37    47    28   NJ US  \n"
     ]
    }
   ],
   "source": [
    "# split NAME column\n",
    "\n",
    "weather_data[['NAME', 'STATE']] = weather_data['NAME'].str.split(',', expand=True)\n",
    "print(weather_data.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STATION', 'NAME', 'DATE', 'AWND', 'PRCP', 'SNOW', 'SNWD', 'TAVG',\n",
       "       'TMAX', 'TMIN', 'STATE'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns\n",
    "weather_data = weather_data.rename(columns={\n",
    "   'STATION': 'station_id',\n",
    "   'NAME': 'station_name',\n",
    "   'DATE': 'date',\n",
    "   'AWND': 'average_wind_speed',\n",
    "   'PRCP': 'precipitation',\n",
    "   'SNOW': 'snowfall',\n",
    "   'SNWD': 'snow_depth',\n",
    "   'TAVG': 'average_temp',\n",
    "   'TMAX': 'max_temp',\n",
    "   'TMIN': 'min_temp',\n",
    "   'STATE': 'state'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['station_id', 'station_name', 'date', 'average_wind_speed',\n",
       "       'precipitation', 'snowfall', 'snow_depth', 'average_temp', 'max_temp',\n",
       "       'min_temp', 'state'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weather_data = weather_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql+psycopg2://thomasdewit:@localhost:5432/citibike_database')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# citibike database\n",
    "\n",
    "new_citibike_tripdata.to_sql('citibike_tripdata', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather database\n",
    "\n",
    "new_weather_data.to_sql('weather_data', engine, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis\n",
    "\n",
    "Possible SQL views:\n",
    "- daily rides and weather combined\n",
    "- Most popular Start/End Stations\n",
    "- Most popular station combo's/routes\n",
    "- most popular time of year\n",
    "- Bike rides per hour of day\n",
    "- Overview of birth years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daily rides and weather combined\n",
    "\n",
    "view_daily_ride_weather = 'daily_ride_weather'\n",
    "query = f'SELECT * FROM {view_daily_ride_weather}'\n",
    "\n",
    "daily_ride_weather = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>count</th>\n",
       "      <th>date</th>\n",
       "      <th>average_wind_speed</th>\n",
       "      <th>precipitation</th>\n",
       "      <th>average_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>163</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>12.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>207</td>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>9.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>276</td>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>10.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>286</td>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>17.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>273</td>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>9.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date  count        date  average_wind_speed  precipitation  \\\n",
       "0  2016-01-01    163  2016-01-01               12.75            0.0   \n",
       "1  2016-01-02    207  2016-01-02                9.40            0.0   \n",
       "2  2016-01-03    276  2016-01-03               10.29            0.0   \n",
       "3  2016-01-04    286  2016-01-04               17.22            0.0   \n",
       "4  2016-01-05    273  2016-01-05                9.84            0.0   \n",
       "\n",
       "   average_temp  \n",
       "0            41  \n",
       "1            36  \n",
       "2            37  \n",
       "3            32  \n",
       "4            19  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_ride_weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code above was not scalable, since I need to fetch data from 8 more views.\n",
    "# So I made a function instead.\n",
    "\n",
    "def fetch_data_from_views(engine, view):\n",
    "    query = f'SELECT * FROM {view}'\n",
    "    dataframe = pd.read_sql(query, engine)\n",
    "    return dataframe\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   start_station_count start_station_name\n",
      "0                28736      Grove St PATH\n",
      "1                19014     Exchange Place\n",
      "2                17137            Sip Ave\n",
      "3                15300      Hamilton Park\n",
      "4                13363       Newport PATH\n"
     ]
    }
   ],
   "source": [
    "popular_start_station = 'popular_start_station'\n",
    "print(fetch_data_from_views(engine, popular_start_station).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   end_station_count end_station_name\n",
      "0              38295    Grove St PATH\n",
      "1              22236   Exchange Place\n",
      "2              15881          Sip Ave\n",
      "3              15418    Hamilton Park\n",
      "4              13533     Newport PATH\n"
     ]
    }
   ],
   "source": [
    "popular_end_station = 'popular_end_station'\n",
    "print(fetch_data_from_views(engine, popular_end_station).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  start_station_name end_station_name  combination_count\n",
      "0      Hamilton Park    Grove St PATH               5742\n",
      "1       Brunswick St    Grove St PATH               5553\n",
      "2    McGinley Square          Sip Ave               4728\n",
      "3      Grove St PATH    Hamilton Park               4135\n",
      "4     Van Vorst Park    Grove St PATH               3954\n"
     ]
    }
   ],
   "source": [
    "popular_station_combos = 'popular_station_combos'\n",
    "print(fetch_data_from_views(engine, popular_station_combos).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       month  count\n",
      "0  2016-01-01 00:00:00+01:00   7479\n",
      "1  2016-02-01 00:00:00+01:00   8250\n",
      "2  2016-03-01 00:00:00+01:00  13511\n",
      "3  2016-04-01 00:00:00+02:00  16342\n",
      "4  2016-05-01 00:00:00+02:00  19488\n"
     ]
    }
   ],
   "source": [
    "popular_month = 'popular_month'\n",
    "print(fetch_data_from_views(engine, popular_month).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             hour  count\n",
      "0 0 days 00:00:00   2533\n",
      "1 0 days 01:00:00   1316\n",
      "2 0 days 02:00:00    802\n",
      "3 0 days 03:00:00    514\n",
      "4 0 days 04:00:00    580\n"
     ]
    }
   ],
   "source": [
    "rides_hour = 'rides_hour'\n",
    "print(fetch_data_from_views(engine, rides_hour).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   birth_year  count\n",
      "0           0  18999\n",
      "1        1900      1\n",
      "2        1934      1\n",
      "3        1937      4\n",
      "4        1940      3\n"
     ]
    }
   ],
   "source": [
    "birth_years = 'birth_years'\n",
    "print(fetch_data_from_views(engine, birth_years).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
